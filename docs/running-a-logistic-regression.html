<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences</title>
  <meta name="description" content="6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences" />
  <meta name="github-repo" content="desmond-ong/stats-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences" />
  
  <meta name="twitter:description" content="6.2 Running a logistic regression | Statistics and Analytics for the Social and Computing Sciences" />
  

<meta name="author" content="Desmond C. Ong" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics-of-logistic-regression.html"/>
<link rel="next" href="not-done-exercises-linear-model-ii.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics and Analytics for the Social and Computing Sciences</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="outline-of-notes.html"><a href="outline-of-notes.html"><i class="fa fa-check"></i>Outline of notes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i>Getting Started</a><ul>
<li class="chapter" data-level="" data-path="getting-started.html"><a href="getting-started.html#how-to-use-r-markdown"><i class="fa fa-check"></i>How to use R Markdown</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html"><i class="fa fa-check"></i>Coding Best Practices</a><ul>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#ensuring-a-reproducible-workflow"><i class="fa fa-check"></i>Ensuring a Reproducible workflow</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#other-coding-best-practices"><i class="fa fa-check"></i>Other Coding Best Practices</a></li>
<li class="chapter" data-level="" data-path="coding-best-practices.html"><a href="coding-best-practices.html#analysis-best-practices"><i class="fa fa-check"></i>Analysis Best Practices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> [Not Done:] Introduction</a></li>
<li class="chapter" data-level="2" data-path="handling-data.html"><a href="handling-data.html"><i class="fa fa-check"></i><b>2</b> Handling Data</a><ul>
<li class="chapter" data-level="2.1" data-path="basics-of-data-wrangling.html"><a href="basics-of-data-wrangling.html"><i class="fa fa-check"></i><b>2.1</b> Basics of Data Wrangling</a></li>
<li class="chapter" data-level="2.2" data-path="wrangling-in-the-tidyverse.html"><a href="wrangling-in-the-tidyverse.html"><i class="fa fa-check"></i><b>2.2</b> Wrangling in the tidyverse</a><ul>
<li><a href="wrangling-in-the-tidyverse.html#the-operator">The <code>%&gt;%</code> operator</a></li>
<li class="chapter" data-level="" data-path="wrangling-in-the-tidyverse.html"><a href="wrangling-in-the-tidyverse.html#wide-to-long-pivot_longer"><i class="fa fa-check"></i>Wide-to-long: pivot_longer()</a></li>
<li class="chapter" data-level="" data-path="wrangling-in-the-tidyverse.html"><a href="wrangling-in-the-tidyverse.html#mutate"><i class="fa fa-check"></i>mutate()</a></li>
<li class="chapter" data-level="" data-path="wrangling-in-the-tidyverse.html"><a href="wrangling-in-the-tidyverse.html#long-to-wide-pivot_wider"><i class="fa fa-check"></i>Long-to-wide: pivot_wider()</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="not-done-a-data-cleaning-pipeline-for-research-projects.html"><a href="not-done-a-data-cleaning-pipeline-for-research-projects.html"><i class="fa fa-check"></i><b>2.3</b> [Not Done:] A data cleaning pipeline for research projects</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="not-done-descriptive-statistics.html"><a href="not-done-descriptive-statistics.html"><i class="fa fa-check"></i><b>3</b> [Not Done:] Descriptive Statistics</a></li>
<li class="chapter" data-level="4" data-path="not-done-data-visualization.html"><a href="not-done-data-visualization.html"><i class="fa fa-check"></i><b>4</b> [Not Done:] Data Visualization</a></li>
<li class="chapter" data-level="5" data-path="the-linear-model-i-linear-regression.html"><a href="the-linear-model-i-linear-regression.html"><i class="fa fa-check"></i><b>5</b> The Linear Model I: Linear Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="basics-of-linear-regression.html"><a href="basics-of-linear-regression.html"><i class="fa fa-check"></i><b>5.1</b> Basics of Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="running-a-regression.html"><a href="running-a-regression.html"><i class="fa fa-check"></i><b>5.2</b> Running a regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="running-a-regression.html"><a href="running-a-regression.html#structure-your-dataset"><i class="fa fa-check"></i><b>5.2.1</b> Structure your dataset</a></li>
<li class="chapter" data-level="5.2.2" data-path="running-a-regression.html"><a href="running-a-regression.html#visualize"><i class="fa fa-check"></i><b>5.2.2</b> Visualize</a></li>
<li class="chapter" data-level="5.2.3" data-path="running-a-regression.html"><a href="running-a-regression.html#running-the-linear-model"><i class="fa fa-check"></i><b>5.2.3</b> Running the linear model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>5.3</b> Ordinary Least Squares Regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#ordinary-least-squares-derivation"><i class="fa fa-check"></i><b>5.3.1</b> Ordinary Least Squares Derivation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html"><i class="fa fa-check"></i><b>5.4</b> Interpreting the output of a regression model</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html#the-coefficient-table"><i class="fa fa-check"></i><b>5.4.1</b> The coefficient table</a></li>
<li class="chapter" data-level="5.4.2" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html#goodness-of-fit-statistics"><i class="fa fa-check"></i><b>5.4.2</b> Goodness-of-fit statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="regression-example1.html"><a href="regression-example1.html"><i class="fa fa-check"></i><b>5.5</b> Examples: Simple Regression</a></li>
<li class="chapter" data-level="5.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>5.6</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.7" data-path="standardized-coefficients.html"><a href="standardized-coefficients.html"><i class="fa fa-check"></i><b>5.7</b> Standardized Coefficients</a></li>
<li class="chapter" data-level="5.8" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html"><i class="fa fa-check"></i><b>5.8</b> Categorical Independent Variables</a><ul>
<li class="chapter" data-level="5.8.1" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#dummy-coding"><i class="fa fa-check"></i><b>5.8.1</b> Dummy Coding</a></li>
<li class="chapter" data-level="5.8.2" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#dummy-coding-with-3-levels"><i class="fa fa-check"></i><b>5.8.2</b> Dummy Coding with 3 levels</a></li>
<li class="chapter" data-level="5.8.3" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#the-reference-group"><i class="fa fa-check"></i><b>5.8.3</b> The Reference Group</a></li>
<li class="chapter" data-level="5.8.4" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#interpreting-categorical-and-continuous-independent-variables"><i class="fa fa-check"></i><b>5.8.4</b> Interpreting categorical and continuous independent variables</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html"><i class="fa fa-check"></i><b>5.9</b> Assumptions behind Linear Regression</a><ul>
<li class="chapter" data-level="5.9.1" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#residual-plots"><i class="fa fa-check"></i><b>5.9.1</b> Residual plots</a></li>
<li class="chapter" data-level="5.9.2" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#not-done-multicollinearity"><i class="fa fa-check"></i><b>5.9.2</b> [Not done:] Multicollinearity</a></li>
<li class="chapter" data-level="5.9.3" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#not-done-autocorrelation"><i class="fa fa-check"></i><b>5.9.3</b> [Not done:] Autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="exercises-linear-model-i.html"><a href="exercises-linear-model-i.html"><i class="fa fa-check"></i><b>5.10</b> Exercises: Linear Model I</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="the-linear-model-ii-logistic-regression.html"><a href="the-linear-model-ii-logistic-regression.html"><i class="fa fa-check"></i><b>6</b> The Linear Model II: Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="basics-of-logistic-regression.html"><a href="basics-of-logistic-regression.html"><i class="fa fa-check"></i><b>6.1</b> Basics of Logistic Regression</a></li>
<li class="chapter" data-level="6.2" data-path="running-a-logistic-regression.html"><a href="running-a-logistic-regression.html"><i class="fa fa-check"></i><b>6.2</b> Running a logistic regression</a></li>
<li class="chapter" data-level="6.3" data-path="not-done-exercises-linear-model-ii.html"><a href="not-done-exercises-linear-model-ii.html"><i class="fa fa-check"></i><b>6.3</b> [Not Done:] Exercises: Linear Model II</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="not-done-the-linear-model-iii-interactions.html"><a href="not-done-the-linear-model-iii-interactions.html"><i class="fa fa-check"></i><b>7</b> [Not Done:] The Linear Model III: Interactions</a></li>
<li class="chapter" data-level="8" data-path="not-done-the-linear-model-iv-model-selection.html"><a href="not-done-the-linear-model-iv-model-selection.html"><i class="fa fa-check"></i><b>8</b> [Not Done:] The Linear Model IV: Model Selection</a></li>
<li class="chapter" data-level="9" data-path="not-done-the-linear-model-v-mixed-effects-linear-models.html"><a href="not-done-the-linear-model-v-mixed-effects-linear-models.html"><i class="fa fa-check"></i><b>9</b> [Not Done:] The Linear Model V: Mixed Effects Linear Models</a></li>
<li class="chapter" data-level="10" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>10</b> [Not Done:] Introduction to Time-Series Data</a></li>
<li class="chapter" data-level="11" data-path="not-done-data-mining.html"><a href="not-done-data-mining.html"><i class="fa fa-check"></i><b>11</b> [Not Done:] Data Mining</a></li>
<li class="chapter" data-level="12" data-path="optimization-i-linear-optimization.html"><a href="optimization-i-linear-optimization.html"><i class="fa fa-check"></i><b>12</b> Optimization I: Linear Optimization</a><ul>
<li class="chapter" data-level="12.1" data-path="what-is-linear-optimization.html"><a href="what-is-linear-optimization.html"><i class="fa fa-check"></i><b>12.1</b> What is Linear Optimization</a></li>
<li class="chapter" data-level="12.2" data-path="objective-functions-decision-variables.html"><a href="objective-functions-decision-variables.html"><i class="fa fa-check"></i><b>12.2</b> Objective Functions &amp; Decision Variables</a><ul>
<li class="chapter" data-level="" data-path="objective-functions-decision-variables.html"><a href="objective-functions-decision-variables.html#jean-the-farmer-objective-function"><i class="fa fa-check"></i>Jean the Farmer: Objective Function</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="constraints.html"><a href="constraints.html"><i class="fa fa-check"></i><b>12.3</b> Constraints</a><ul>
<li class="chapter" data-level="" data-path="constraints.html"><a href="constraints.html#jean-the-farmer-constraints"><i class="fa fa-check"></i>Jean the Farmer: Constraints</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="solving-the-optimization-model.html"><a href="solving-the-optimization-model.html"><i class="fa fa-check"></i><b>12.4</b> Solving the Optimization Model</a></li>
<li class="chapter" data-level="12.5" data-path="using-r-to-solve-linear-optimization.html"><a href="using-r-to-solve-linear-optimization.html"><i class="fa fa-check"></i><b>12.5</b> Using R to solve Linear Optimization</a></li>
<li class="chapter" data-level="12.6" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html"><i class="fa fa-check"></i><b>12.6</b> Sensitivity Analysis</a><ul>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#varying-objective-function-coefficients"><i class="fa fa-check"></i>Varying objective function coefficients</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#varying-constraint-values-shadow-prices"><i class="fa fa-check"></i>Varying Constraint Values (Shadow Prices)</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#binding-vs-non-binding-constraints"><i class="fa fa-check"></i>Binding vs non-binding constraints</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#summarizing-sensitivity-analyses"><i class="fa fa-check"></i>Summarizing sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="linear-optimization-summary.html"><a href="linear-optimization-summary.html"><i class="fa fa-check"></i><b>12.7</b> Linear Optimization Summary</a></li>
<li class="chapter" data-level="12.8" data-path="not-done-exercises.html"><a href="not-done-exercises.html"><i class="fa fa-check"></i><b>12.8</b> [NOT DONE] Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="optimization-ii-integer-valued-optimization.html"><a href="optimization-ii-integer-valued-optimization.html"><i class="fa fa-check"></i><b>13</b> Optimization II: Integer-valued Optimization</a><ul>
<li class="chapter" data-level="13.1" data-path="integer-valued-decision-variables.html"><a href="integer-valued-decision-variables.html"><i class="fa fa-check"></i><b>13.1</b> Integer-valued decision variables</a></li>
<li class="chapter" data-level="13.2" data-path="not-done-from-real-valued-to-integer-solutions.html"><a href="not-done-from-real-valued-to-integer-solutions.html"><i class="fa fa-check"></i><b>13.2</b> [NOT DONE] From real-valued to integer solutions</a></li>
<li class="chapter" data-level="13.3" data-path="logical-constraints.html"><a href="logical-constraints.html"><i class="fa fa-check"></i><b>13.3</b> Logical Constraints</a><ul>
<li class="chapter" data-level="13.3.1" data-path="logical-constraints.html"><a href="logical-constraints.html#logical-constraints-example-planning-university-courses"><i class="fa fa-check"></i><b>13.3.1</b> Logical Constraints Example: Planning university courses</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="integer-optimization-summary.html"><a href="integer-optimization-summary.html"><i class="fa fa-check"></i><b>13.4</b> Integer Optimization Summary</a></li>
<li class="chapter" data-level="13.5" data-path="not-done-exercises-1.html"><a href="not-done-exercises-1.html"><i class="fa fa-check"></i><b>13.5</b> [NOT DONE] Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="not-done-simulations-i.html"><a href="not-done-simulations-i.html"><i class="fa fa-check"></i><b>14</b> [Not Done:] Simulations (I)</a><ul>
<li class="chapter" data-level="14.1" data-path="not-done-monte-carlo-simulations.html"><a href="not-done-monte-carlo-simulations.html"><i class="fa fa-check"></i><b>14.1</b> [Not Done:] Monte Carlo simulations</a></li>
<li class="chapter" data-level="14.2" data-path="not-done-the-bootstrap.html"><a href="not-done-the-bootstrap.html"><i class="fa fa-check"></i><b>14.2</b> [Not Done:] The Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="not-done-simulations-ii-statistics-in-machine-learning.html"><a href="not-done-simulations-ii-statistics-in-machine-learning.html"><i class="fa fa-check"></i><b>15</b> [Not Done:] Simulations (II): Statistics in Machine Learning</a></li>
<li class="chapter" data-level="16" data-path="not-done-book-summary.html"><a href="not-done-book-summary.html"><i class="fa fa-check"></i><b>16</b> [Not Done:] Book Summary ??</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics and Analytics for the Social and Computing Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="running-a-logistic-regression" class="section level2">
<h2><span class="header-section-number">6.2</span> Running a logistic regression</h2>
<p><span class="badge badge-bt"> BT1101 </span></p>
<p>The syntax for running a logistic regression is almost the same as a linear regression, just that the call is <code>glm()</code> for <strong>g</strong>eneral <strong>l</strong>inear <strong>m</strong>odel, with an additional specification of <code>family = binomial</code>, which tells <code>glm</code> to run logistic regression. (Other <code>family</code> options produce other types of general linear regression, such as probit regression, etc.)</p>
<p>Now, the good news is that R handles a lot of this complication for you, when it can. For example, we <strong>do not</strong> have to manually calculate the odds ourselves. All we have to do is make sure our variable is a binary factor, then we can just call <code>glm()</code>.</p>
<blockquote>
<p>Note that, just like categorical IVs, when we do logistic regression with a categorical DV, we also have a <strong>reference group</strong>, so do use the <code>levels()</code> function to check.</p>
</blockquote>
<p>Let’s generate a simple dataset with two independent variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, and use them to predict <span class="math inline">\(\text{Purchase}\)</span>, a binary yes/no variable.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="co"># logistic</span></a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb45-3" data-line-number="3">df2 =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x1=</span><span class="kw">rnorm</span>(<span class="dv">20</span>,<span class="dv">0</span>,<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">seq</span>(<span class="dv">20</span>,<span class="dv">1</span>),</a>
<a class="sourceLine" id="cb45-4" data-line-number="4">                 <span class="dt">x2=</span><span class="kw">rnorm</span>(<span class="dv">20</span>,<span class="dv">5</span>,<span class="dv">3</span>),</a>
<a class="sourceLine" id="cb45-5" data-line-number="5">                 <span class="dt">Purchase =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>), <span class="dt">each=</span><span class="dv">10</span>)),</a>
<a class="sourceLine" id="cb45-6" data-line-number="6">                                   <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>))</a>
<a class="sourceLine" id="cb45-7" data-line-number="7"><span class="kw">levels</span>(df2<span class="op">$</span>Purchase) </a></code></pre></div>
<pre><code>## [1] &quot;No&quot;  &quot;Yes&quot;</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="co">## This means that &quot;No&quot; is the `base group`, and `p` is the probability of &quot;Yes&quot;.</span></a></code></pre></div>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="co"># next, running a logistic regression via a general linear model</span></a>
<a class="sourceLine" id="cb48-2" data-line-number="2">fit_log1 &lt;-<span class="st"> </span><span class="kw">glm</span>(Purchase <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, df2)</a>
<a class="sourceLine" id="cb48-3" data-line-number="3"><span class="kw">summary</span>(fit_log1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Purchase ~ x1 + x2, family = &quot;binomial&quot;, data = df2)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.96587  -0.37136   0.00399   0.54011   1.64780  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  -4.0054     2.4320  -1.647   0.0996 .
## x1            0.3954     0.1653   2.393   0.0167 *
## x2           -0.1281     0.3062  -0.418   0.6758  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 27.726  on 19  degrees of freedom
## Residual deviance: 14.597  on 17  degrees of freedom
## AIC: 20.597
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>The summary output looks almost the same too as a <code>lm()</code> call. Let’s focus on the coefficient table, and reproduce the regression equation to help us in the interpretation.</p>
<p><span class="math display">\[\text{logit}(p) \equiv \log\frac{p}{1-p} = b_0 + b_1 X_1 + b_2X_2\]</span></p>
<p>Just like in linear regression, <span class="math inline">\(b_0\)</span> is the mean value of the left-hand-side when all the <span class="math inline">\(X\)</span> on the right hand side are zero. Hence, <span class="math inline">\(b_0\)</span> is the log-odds of the event occurring when <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are both zero (this part is the same as what we’ve covered previously). So this means that when <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are both zero, the log-odds of purchasing an item is -4.005. Conversely, we can also say that the odds of purchasing this item is <code>exp</code>(-4.005), or 0.018.
This means that <span class="math inline">\(\frac{p}{1-p}\)</span> is 0.018.</p>
<p>Next, let’s move onto <span class="math inline">\(b_1\)</span>. <span class="math inline">\(b_1\)</span> is the expected increase in log-odds per unit increase of <span class="math inline">\(X_1\)</span>, holding <span class="math inline">\(X_2\)</span> constant. This is the same as linear regression.</p>
<p>And similarly, <span class="math inline">\(b_2\)</span> is the expected increase in log-odds per unit increase of <span class="math inline">\(X_2\)</span>, holding <span class="math inline">\(X_1\)</span> constant. Note that <span class="math inline">\(b_2\)</span> is negative, so increasing <span class="math inline">\(X_2\)</span> will decrease the log-odds. (But in this case, it’s not significant anyway)</p>
<p>Now, let’s take some numbers to build intuition. Every unit-increase of <span class="math inline">\(X_1\)</span> increases the log-odds by 0.3954. Conversely, every unit-increase of <span class="math inline">\(X_1\)</span> multiplies the odds by exp(0.3954) = 1.48. i.e., the odds increase by 48%</p>
<ul>
<li>Check: When <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are 0, the odds are <code>exp</code>(-4.005) = 0.0182.</li>
<li>If we now increase <span class="math inline">\(X_1\)</span> to 1, the odds are now <code>exp</code>(-4.005 + 0.395), or 0.0271.</li>
<li>The odds have increased by (0.0271-0.0182)/0.0182 ~ 48% (if we kept more decimal places)</li>
</ul>
<p>For example, if <span class="math inline">\(X_1\)</span> is “Number of A-list celebrities endorsing your product”, then getting one additional celebrity endorsement would, in expectation, increase each customer’s odds of purchasing your product by 48%. (not increasing probability, but odds)</p>
<p>This table summarizes the interpretations:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Coefficient</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(<span class="math inline">\(b_0\)</span>)</td>
<td>Log-odds when <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are both zero. Odds of purchasing = exp(-4.0054) = 0.018</td>
</tr>
<tr class="even">
<td>(<span class="math inline">\(b_1\)</span>)</td>
<td>Expected increase in log-odds of event per unit-increase of <span class="math inline">\(X_1\)</span>, holding <span class="math inline">\(X_2\)</span> constant.</td>
</tr>
<tr class="odd">
<td>(<span class="math inline">\(b_2\)</span>)</td>
<td>Expected increase in log-odds of event per unit-increase of <span class="math inline">\(X_2\)</span>, holding <span class="math inline">\(X_1\)</span> constant.</td>
</tr>
</tbody>
</table>
<p>The rest of the coefficient table is the similar to the <code>lm()</code>. However, instead of these coefficients following a <span class="math inline">\(t\)</span> distribution, they follow a <span class="math inline">\(z\)</span> distribution. The interpretation of the standard error, <span class="math inline">\(z\)</span> values, and <span class="math inline">\(p\)</span> values are similar. Thus, in this table, the coefficient <span class="math inline">\(X_1\)</span> is statistically significant at the <span class="math inline">\(\alpha=0.05\)</span> confidence level (<span class="math inline">\(p&lt;.05\)</span>)</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics-of-logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="not-done-exercises-linear-model-ii.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
