<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.4 Interpreting the output of a regression model | Some notes on Statistics and Data Analytics (Working Title)</title>
  <meta name="description" content="A collection of statistics notes for data analytics." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="5.4 Interpreting the output of a regression model | Some notes on Statistics and Data Analytics (Working Title)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of statistics notes for data analytics." />
  <meta name="github-repo" content="desmond-ong/stats-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.4 Interpreting the output of a regression model | Some notes on Statistics and Data Analytics (Working Title)" />
  
  <meta name="twitter:description" content="A collection of statistics notes for data analytics." />
  

<meta name="author" content="Desmond C. Ong" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ordinary-least-squares-regression.html"/>
<link rel="next" href="regression-example1.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Some notes on Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="outline-of-notes.html"><a href="outline-of-notes.html"><i class="fa fa-check"></i>Outline of notes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="not-done-getting-started.html"><a href="not-done-getting-started.html"><i class="fa fa-check"></i>[Not Done:] Getting Started</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> [Not Done:] Introduction</a></li>
<li class="chapter" data-level="2" data-path="not-done-descriptive-statistics.html"><a href="not-done-descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> [Not Done:] Descriptive Statistics</a></li>
<li class="chapter" data-level="3" data-path="not-done-handling-data.html"><a href="not-done-handling-data.html"><i class="fa fa-check"></i><b>3</b> [Not Done:] Handling Data</a></li>
<li class="chapter" data-level="4" data-path="not-done-data-visualization.html"><a href="not-done-data-visualization.html"><i class="fa fa-check"></i><b>4</b> [Not Done:] Data Visualization</a></li>
<li class="chapter" data-level="5" data-path="the-linear-model-i-linear-regression.html"><a href="the-linear-model-i-linear-regression.html"><i class="fa fa-check"></i><b>5</b> The Linear Model I: Linear Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="basics-of-linear-regression.html"><a href="basics-of-linear-regression.html"><i class="fa fa-check"></i><b>5.1</b> Basics of Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="running-a-regression.html"><a href="running-a-regression.html"><i class="fa fa-check"></i><b>5.2</b> Running a regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="running-a-regression.html"><a href="running-a-regression.html#structure-your-dataset"><i class="fa fa-check"></i><b>5.2.1</b> Structure your dataset</a></li>
<li class="chapter" data-level="5.2.2" data-path="running-a-regression.html"><a href="running-a-regression.html#visualize"><i class="fa fa-check"></i><b>5.2.2</b> Visualize</a></li>
<li class="chapter" data-level="5.2.3" data-path="running-a-regression.html"><a href="running-a-regression.html#running-the-linear-model"><i class="fa fa-check"></i><b>5.2.3</b> Running the linear model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>5.3</b> Ordinary Least Squares Regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#ordinary-least-squares-derivation"><i class="fa fa-check"></i><b>5.3.1</b> Ordinary Least Squares Derivation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html"><i class="fa fa-check"></i><b>5.4</b> Interpreting the output of a regression model</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html#the-coefficient-table"><i class="fa fa-check"></i><b>5.4.1</b> The coefficient table</a></li>
<li class="chapter" data-level="5.4.2" data-path="interpreting-the-output-of-a-regression-model.html"><a href="interpreting-the-output-of-a-regression-model.html#goodness-of-fit-statistics"><i class="fa fa-check"></i><b>5.4.2</b> Goodness-of-fit statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="regression-example1.html"><a href="regression-example1.html"><i class="fa fa-check"></i><b>5.5</b> Examples: Simple Regression</a></li>
<li class="chapter" data-level="5.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>5.6</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.7" data-path="standardized-coefficients.html"><a href="standardized-coefficients.html"><i class="fa fa-check"></i><b>5.7</b> Standardized Coefficients</a></li>
<li class="chapter" data-level="5.8" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html"><i class="fa fa-check"></i><b>5.8</b> Categorical Independent Variables</a><ul>
<li class="chapter" data-level="5.8.1" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#dummy-coding"><i class="fa fa-check"></i><b>5.8.1</b> Dummy Coding</a></li>
<li class="chapter" data-level="5.8.2" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#dummy-coding-with-3-levels"><i class="fa fa-check"></i><b>5.8.2</b> Dummy Coding with 3 levels</a></li>
<li class="chapter" data-level="5.8.3" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#the-reference-group"><i class="fa fa-check"></i><b>5.8.3</b> The Reference Group</a></li>
<li class="chapter" data-level="5.8.4" data-path="categorical-independent-variables.html"><a href="categorical-independent-variables.html#interpreting-categorical-and-continuous-independent-variables"><i class="fa fa-check"></i><b>5.8.4</b> Interpreting categorical and continuous independent variables</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html"><i class="fa fa-check"></i><b>5.9</b> Assumptions behind Linear Regression</a><ul>
<li class="chapter" data-level="5.9.1" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#residual-plots"><i class="fa fa-check"></i><b>5.9.1</b> Residual plots</a></li>
<li class="chapter" data-level="5.9.2" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#not-done-multicollinearity"><i class="fa fa-check"></i><b>5.9.2</b> [Not done:] Multicollinearity</a></li>
<li class="chapter" data-level="5.9.3" data-path="assumptions-behind-linear-regression.html"><a href="assumptions-behind-linear-regression.html#not-done-autocorrelation"><i class="fa fa-check"></i><b>5.9.3</b> [Not done:] Autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="not-done-exercises-linear-model-i.html"><a href="not-done-exercises-linear-model-i.html"><i class="fa fa-check"></i><b>5.10</b> [Not Done:] Exercises: Linear Model I</a></li>
<li class="chapter" data-level="5.11" data-path="todo-discuss-transformations.html"><a href="todo-discuss-transformations.html"><i class="fa fa-check"></i><b>5.11</b> [todo:] Discuss Transformations?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="the-linear-model-ii-logistic-regression.html"><a href="the-linear-model-ii-logistic-regression.html"><i class="fa fa-check"></i><b>6</b> The Linear Model II: Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="basics-of-logistic-regression.html"><a href="basics-of-logistic-regression.html"><i class="fa fa-check"></i><b>6.1</b> Basics of Logistic Regression</a></li>
<li class="chapter" data-level="6.2" data-path="running-a-logistic-regression.html"><a href="running-a-logistic-regression.html"><i class="fa fa-check"></i><b>6.2</b> Running a logistic regression</a></li>
<li class="chapter" data-level="6.3" data-path="not-done-exercises-linear-model-ii.html"><a href="not-done-exercises-linear-model-ii.html"><i class="fa fa-check"></i><b>6.3</b> [Not Done:] Exercises: Linear Model II</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="not-done-the-linear-model-iii-interactions.html"><a href="not-done-the-linear-model-iii-interactions.html"><i class="fa fa-check"></i><b>7</b> [Not Done:] The Linear Model III: Interactions</a></li>
<li class="chapter" data-level="8" data-path="not-done-the-linear-model-iv-model-selection.html"><a href="not-done-the-linear-model-iv-model-selection.html"><i class="fa fa-check"></i><b>8</b> [Not Done:] The Linear Model IV: Model Selection</a></li>
<li class="chapter" data-level="9" data-path="not-done-the-linear-model-v-mixed-effects-linear-models.html"><a href="not-done-the-linear-model-v-mixed-effects-linear-models.html"><i class="fa fa-check"></i><b>9</b> [Not Done:] The Linear Model V: Mixed Effects Linear Models</a></li>
<li class="chapter" data-level="10" data-path="not-done-simulations.html"><a href="not-done-simulations.html"><i class="fa fa-check"></i><b>10</b> [Not Done:] Simulations</a></li>
<li class="chapter" data-level="11" data-path="not-done-data-mining.html"><a href="not-done-data-mining.html"><i class="fa fa-check"></i><b>11</b> [Not Done:] Data Mining</a></li>
<li class="chapter" data-level="12" data-path="optimization-i-linear-optimization.html"><a href="optimization-i-linear-optimization.html"><i class="fa fa-check"></i><b>12</b> Optimization I: Linear Optimization</a><ul>
<li class="chapter" data-level="12.1" data-path="what-is-linear-optimization.html"><a href="what-is-linear-optimization.html"><i class="fa fa-check"></i><b>12.1</b> What is Linear Optimization</a></li>
<li class="chapter" data-level="12.2" data-path="objective-functions-decision-variables.html"><a href="objective-functions-decision-variables.html"><i class="fa fa-check"></i><b>12.2</b> Objective Functions &amp; Decision Variables</a><ul>
<li class="chapter" data-level="" data-path="objective-functions-decision-variables.html"><a href="objective-functions-decision-variables.html#jean-the-farmer-objective-function"><i class="fa fa-check"></i>Jean the Farmer: Objective Function</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="constraints.html"><a href="constraints.html"><i class="fa fa-check"></i><b>12.3</b> Constraints</a><ul>
<li class="chapter" data-level="" data-path="constraints.html"><a href="constraints.html#jean-the-farmer-constraints"><i class="fa fa-check"></i>Jean the Farmer: Constraints</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="solving-the-optimization-model.html"><a href="solving-the-optimization-model.html"><i class="fa fa-check"></i><b>12.4</b> Solving the Optimization Model</a></li>
<li class="chapter" data-level="12.5" data-path="using-r-to-solve-linear-optimization.html"><a href="using-r-to-solve-linear-optimization.html"><i class="fa fa-check"></i><b>12.5</b> Using R to solve Linear Optimization</a></li>
<li class="chapter" data-level="12.6" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html"><i class="fa fa-check"></i><b>12.6</b> Sensitivity Analysis</a><ul>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#varying-objective-function-coefficients"><i class="fa fa-check"></i>Varying objective function coefficients</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#varying-constraint-values-shadow-prices"><i class="fa fa-check"></i>Varying Constraint Values (Shadow Prices)</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#binding-vs-non-binding-constraints"><i class="fa fa-check"></i>Binding vs non-binding constraints</a></li>
<li class="chapter" data-level="" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#summarizing-sensitivity-analyses"><i class="fa fa-check"></i>Summarizing sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="linear-optimization-summary.html"><a href="linear-optimization-summary.html"><i class="fa fa-check"></i><b>12.7</b> Linear Optimization Summary</a></li>
<li class="chapter" data-level="12.8" data-path="not-done-exercises.html"><a href="not-done-exercises.html"><i class="fa fa-check"></i><b>12.8</b> [NOT DONE] Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="optimization-ii-integer-valued-optimization.html"><a href="optimization-ii-integer-valued-optimization.html"><i class="fa fa-check"></i><b>13</b> Optimization II: Integer-valued Optimization</a><ul>
<li class="chapter" data-level="13.1" data-path="integer-valued-decision-variables.html"><a href="integer-valued-decision-variables.html"><i class="fa fa-check"></i><b>13.1</b> Integer-valued decision variables</a></li>
<li class="chapter" data-level="13.2" data-path="not-done-from-real-valued-to-integer-solutions.html"><a href="not-done-from-real-valued-to-integer-solutions.html"><i class="fa fa-check"></i><b>13.2</b> [NOT DONE] From real-valued to integer solutions</a></li>
<li class="chapter" data-level="13.3" data-path="logical-constraints.html"><a href="logical-constraints.html"><i class="fa fa-check"></i><b>13.3</b> Logical Constraints</a><ul>
<li class="chapter" data-level="13.3.1" data-path="logical-constraints.html"><a href="logical-constraints.html#logical-constraints-example-planning-university-courses"><i class="fa fa-check"></i><b>13.3.1</b> Logical Constraints Example: Planning university courses</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="integer-optimization-summary.html"><a href="integer-optimization-summary.html"><i class="fa fa-check"></i><b>13.4</b> Integer Optimization Summary</a></li>
<li class="chapter" data-level="13.5" data-path="not-done-exercises-1.html"><a href="not-done-exercises-1.html"><i class="fa fa-check"></i><b>13.5</b> [NOT DONE] Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="not-done-book-summary.html"><a href="not-done-book-summary.html"><i class="fa fa-check"></i><b>14</b> [Not Done:] Book Summary ??</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Some notes on Statistics and Data Analytics (Working Title)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpreting-the-output-of-a-regression-model" class="section level2">
<h2><span class="header-section-number">5.4</span> Interpreting the output of a regression model</h2>
<p><span class="badge badge-bt"> BT1101 </span></p>
<p>In this section we’ll be going over the different parts of the linear model output. First, we’ll talk about the coefficient table, then we’ll talk about goodness-of-fit statistics.</p>
<p>Let’s re-run the same model from before:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">fit1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Y<span class="op">~</span>X, df1)</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="kw">summary</span>(fit1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X, data = df1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.0781 -0.5736  0.1260  0.3071  1.5452 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -2.26117    0.46171  -4.897 0.000851 ***
## X            2.10376    0.07804  26.956 6.44e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8185 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.9878, Adjusted R-squared:  0.9864 
## F-statistic: 726.6 on 1 and 9 DF,  p-value: 6.442e-10</code></pre>
<p>First, <code>summary()</code> helpfully reiterates the formula that you put in. This is useful to check that it’s running what you thought it ran.</p>
<pre><code>Call:
lm(formula = Y ~ X, data = df1)</code></pre>
<p>It also tells you the minimum, 1st quantile (25%-ile), median, 3rd quantile (75%-ile), and maximum of the residuals (<span class="math inline">\(e_i = Y_i - \hat{Y_i}\)</span>). That is, the minimum residual error of this model is -1.0781, the median residual error is 0.1260, and the maximum is 1.5452.</p>
<pre><code>Residuals:
    Min      1Q  Median      3Q     Max 
-1.0781 -0.5736  0.1260  0.3071  1.5452 </code></pre>
<div id="the-coefficient-table" class="section level3">
<h3><span class="header-section-number">5.4.1</span> The coefficient table</h3>
<p>Let’s turn next to the coefficient table.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">summary</span>(fit1)<span class="op">$</span>coeff</a></code></pre></div>
<pre><code>##              Estimate Std. Error   t value    Pr(&gt;|t|)
## (Intercept) -2.261167 0.46170984 -4.897376 8.50721e-04
## X            2.103757 0.07804321 26.956313 6.44250e-10</code></pre>
<p>Let’s focus on the “Estimate” column. These are the point estimate of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, for the equation <span class="math display">\[Y= b_0 + b_1 X\]</span></p>
<p>What do these numbers mean?</p>
<blockquote>
<p><span class="math inline">\(b_0\)</span>: The mean value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> is zero</p>
</blockquote>
<p>The meaning of the intercept, <span class="math inline">\(b_0\)</span>, is pretty straightforward. It is the average value of the dependent variable <span class="math inline">\(Y\)</span> when the independent variable <span class="math inline">\(X\)</span> is set to 0. (Graphically, it is the vertical intercept: the point at which the line crosses the vertical axis.)</p>
<blockquote>
<p><span class="math inline">\(b_1\)</span>: According to the model, a one-unit change in <span class="math inline">\(X\)</span> results in a <span class="math inline">\(b_1\)</span>-unit change in <span class="math inline">\(Y\)</span></p>
</blockquote>
<p>The coefficient on <span class="math inline">\(X\)</span>, <span class="math inline">\(b_1\)</span>, captures the magnitude of change in <span class="math inline">\(Y\)</span>, per unit-change in <span class="math inline">\(X\)</span>. Graphically, this is the slope of the regression line; if <span class="math inline">\(b_1\)</span> is larger, the line will have a steeper slope. Conversely, if <span class="math inline">\(b_1\)</span> is smaller in magnitude, the line will have a more shallow slope. If <span class="math inline">\(b_1\)</span> is positive, the slope will slope upwards <code>/</code>, otherwise if <span class="math inline">\(b_1\)</span> is negative, the slope will go downwards <code>\</code>.</p>
<div id="example-interpreting-simple-regression-coefficients" class="section level4 unnumbered">
<h4>Example: Interpreting Simple Regression Coefficients</h4>
<p>Let’s go through an example. Let’s say we fit a model to predict our monthly profit given the amount that we spent on advertising. Both Profit and Expenditure are measured in $.</p>
<p><span class="math display">\[\text{Profit} = -2500 + 3.21* \text{ExpenditureOnAdvertising}\]</span></p>
<table>
<thead>
<tr class="header">
<th>Coefficient</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(<span class="math inline">\(b_0\)</span>)</td>
<td>Monthly profit is -$2500 without any money spent on advertising.</td>
</tr>
<tr class="even">
<td>(<span class="math inline">\(b_1\)</span>)</td>
<td>For every dollar spent on Advertising, Profit increases by $3.21</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Q: Why could profit be negative here?</p>
</blockquote>
<p>Negative (or otherwise unusual) intercepts arise all the time in linear regression. In this example, this just means that, if we spent $0 on advertising, we would still incur a negative profit of $2,500, which could be due to omitted variables such as the amount we have to spent on rent, wages, and other upkeep.</p>
<blockquote>
<p>Note that it is very important to be aware of the <strong>units</strong> that each of the variables, both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, are measured in. This will ensure accurate interpretation of the coefficients!</p>
</blockquote>
</div>
<div id="the-rest-of-the-coefficient-table" class="section level4 unnumbered">
<h4>The rest of the coefficient table</h4>
<p>The estimated value of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are given in the first column (<code>Estimate</code>) of the coefficient table. Next to the estimates, we have the standard error of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, which gives us a sense of the error associated with our estimate.</p>
<p>In the third column, we have the <code>t value</code>. This is the t-statistic for a one-sample t-test comparing this coefficient to zero. That is, it is the one-sample t-test for the null hypothesis that the coefficient is zero, against the alternative, two-sided hypothesis that it is not zero:
<span class="math display">\[ H_0: b_j = 0 \\ H_1: b_j \neq 0 \]</span></p>
<p>In fact, the t value here, is simply the Estimate divided by the Standard Error. (You can check it yourself!)
So with this t value, and the degrees of freedom of the model, we can actually calculate the <code>p value</code> for such a t test. R helpfully does this for you, and this is given in the fourth column, <code>Pr(&gt;|t|)</code>. We can see that these numbers in this example are quite small, so both <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are statistically different from zero.</p>
<p>To the right of the <code>Pr(&gt;|t|)</code> column, R will helpfully print out certain significance codes.</p>
<ul>
<li>If <span class="math inline">\(p\)</span> is between 0.1 and 0.05, R will print a <code>.</code>.</li>
<li>If <span class="math inline">\(p\)</span> is less than 0.05 (<span class="math inline">\(\alpha\)</span>=5% level of significance) but greater than 0.01 (1%), R will print a single <code>*</code>.</li>
<li>If <span class="math inline">\(p\)</span> is less than 0.01 but greater than 0.001, R will print out two asteriks, <code>**</code>.</li>
<li>Finally, if <span class="math inline">\(p\)</span> is less than 0.001, R will print out three asterisks, <code>***</code>.</li>
</ul>
</div>
</div>
<div id="goodness-of-fit-statistics" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Goodness-of-fit statistics</h3>
<p>Finally we’ll look at the last part of the summary output.</p>
<pre><code>## Residual standard error: 0.8185 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.9878, Adjusted R-squared:  0.9864 
## F-statistic: 726.6 on 1 and 9 DF,  p-value: 6.442e-10</code></pre>
<p>First, note that R will helpfully print out whether or not there were observations missing in our data.</p>
<blockquote>
<p>(1 observation deleted due to missingness)</p>
</blockquote>
<p>If, for any data point, either the <span class="math inline">\(X\)</span> value, or the <span class="math inline">\(Y\)</span> value (or both) are missing, then R will remove that observation from the linear model, and report it in the output. This is always something useful to check: do we have an abnormally large number of missing observations that we not expect? For example, perhaps one of the variables has a large number of missing observations? Or maybe when we were calculating new variables, we did not consider certain situations, and so end up with a lot of missing variables. (Or maybe we made a typo in our code!). This is always a good safety check before proceeding further. (Note that if there are no missing observations, R will omit this line).</p>
<p>Next, we’ll discuss a very important statistic, called the coefficient of determination, or <span class="math inline">\(R^2\)</span> (“R-squared”), which is a measure of the <strong>proportion of variance explained by the model</strong>. <span class="math inline">\(R^2\)</span> is a number that always lies between 0 and 1. An <span class="math inline">\(R^2\)</span> of 1 means it’s a perfect model, it explains all of the variance (all the data points lie on the line. Alternatively, all the residuals are 0).</p>
<p>The total amount of variability of the data is captured in something called the Total Sum of Squares, which is the sum of the difference between each data point <span class="math inline">\(Y_i\)</span> and the mean <span class="math inline">\(\bar{Y}\)</span> (this is also related to the variance of <span class="math inline">\(Y\)</span>):
<span class="math display">\[\begin{align}
\text{Total Sum of Squares} \equiv \sum_i \left(Y_i - \bar{Y} \right)^2
\end{align}\]</span></p>
<p>The amount of variability that is explained by our model (which predicts <span class="math inline">\(\hat{Y}\)</span>) is given by the Regression Sum of Squares, which is the sum of the squared error between our model predictions and the mean <span class="math inline">\(\bar{Y}\)</span>:</p>
<p><span class="math display">\[\begin{align}
\text{Regression Sum of Squares} \equiv \sum_i \left(\hat{Y_i} - \bar{Y} \right)^2
\end{align}\]</span></p>
<p>And finally, the leftover amount of variability, also called the Residual Sum of Squares, is basically the difference between our model predictions <span class="math inline">\(\hat{Y}\)</span> and the actual data points <span class="math inline">\(Y\)</span>. This was the term that Ordinary Least Squares regression tries to minimize, which we saw in the last Section.</p>
<p><span class="math display">\[\begin{align}
\text{Residual Sum of Squares} \equiv \sum_i \left(Y_i - \hat{Y_i} \right)^2
\end{align}\]</span></p>
<p>As it turns out, the Total Sum of Squares is made up of these two parts: the Regression Sum of Squares (or “<em>Explained</em>” Sum of Squares), and the Residual Sum of Squares (or the “<em>Unexplained</em>” Sum of Squares).</p>
<p><span class="math display">\[\begin{align}
\text{Total Sum of Squares} \equiv \text{Regression Sum of Squares} + \text{Residual Sum of Squares}
\end{align}\]</span></p>
<p><span class="math inline">\(R^2\)</span> basically measures the proportion of explained variance over the total variance. In other words:</p>
<p><span class="math display">\[\begin{align}
R^2 &amp;\equiv \frac{\text{Regression Sum of Squares}}{\text{Total Sum of Squares}} \\
&amp;\equiv 1 - \frac{\text{Residual Sum of Squares}}{\text{Total Sum of Squares}} 
\end{align}\]</span></p>
<p>You can read off the <span class="math inline">\(R^2\)</span> value from the field indicated by “Multiple R-squared”, i.e.,</p>
<blockquote>
<p>## Multiple R-squared: 0.9878, …</p>
</blockquote>
<p>In the output above, the <span class="math inline">\(R^2\)</span> is 0.9878; this means that this model explains 98.8% of the variance. That’s really high!</p>
<p>Now, how good is a good <span class="math inline">\(R^2\)</span>? Unfortunately there’s no good answer, because it really depends on contexts. In some fields and in some contexts, even an <span class="math inline">\(R^2\)</span> of .10 to .20 could be really good. In other fields, maybe we would expect <span class="math inline">\(R^2\)</span>s of .80 or .90!</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ordinary-least-squares-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-example1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
